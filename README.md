# Chatbot de Soporte TÃ©cnico Basado en DocumentaciÃ³n ğŸ¤–

Un **chatbot de IA** que responde preguntas tÃ©cnicas basadas en documentaciÃ³n, utilizando **LangChain, FAISS y Modelos de Lenguaje Grandes (LLMs)**. Este proyecto demuestra habilidades en **procesamiento de lenguaje natural (NLP), recuperaciÃ³n de informaciÃ³n y despliegue de modelos generativos**.

---

## **ğŸ“Œ CaracterÃ­sticas Clave**
âœ… Carga y procesamiento de documentos (PDF, DOCX, TXT).
âœ… **BÃºsqueda semÃ¡ntica avanzada** con embeddings y FAISS.
âœ… **GeneraciÃ³n de respuestas contextualizadas** usando **LLMs** (FLAN-T5).
âœ… Escalable y adaptable a diferentes dominios tÃ©cnicos.

---

## **ğŸ¤– Modelos de Lenguaje Grandes (LLMs) Utilizados**
Este proyecto aprovecha **LLMs** para generar respuestas precisas y detalladas basadas en el contenido de los documentos. Los LLMs son modelos de IA entrenados con grandes cantidades de texto, capaces de entender y generar lenguaje humano de manera coherente.

### **Modelos Utilizados**
| Modelo               | Tipo               | Uso en el Proyecto                                                                 |
|----------------------|--------------------|------------------------------------------------------------------------------------|
| **FLAN-T5 (google/flan-t5-base)** | Modelo de generaciÃ³n de texto | Genera respuestas detalladas a preguntas tÃ©cnicas basadas en el contexto del documento. |
| **Sentence Transformers (all-mpnet-base-v2)** | Modelo de embeddings | Convierte fragmentos de texto en vectores para bÃºsqueda semÃ¡ntica con FAISS.       |

### **Â¿Por quÃ© FLAN-T5?**
- **FLAN-T5** es un modelo de **instruction tuning** (ajustado para seguir instrucciones), lo que lo hace ideal para tareas de **question-answering** y generaciÃ³n de respuestas contextualizadas.
- Es mÃ¡s eficiente que modelos como GPT-3 para tareas especÃ­ficas, y su versiÃ³n `base` es lo suficientemente ligera para ejecutarse en entornos con recursos limitados (como Google Colab).

### **Â¿Por quÃ© Sentence Transformers?**
- **all-mpnet-base-v2** genera **embeddings** (representaciones vectoriales) de alta calidad, permitiendo buscar informaciÃ³n relevante en los documentos incluso si las palabras clave no coinciden exactamente.

---

## **ğŸ›  TecnologÃ­as Utilizadas**
- **LangChain**: Framework para conectar LLMs con fuentes de datos externas.
- **FAISS (Facebook)**: Biblioteca para bÃºsqueda eficiente de similitud en espacios vectoriales.
- **Hugging Face Transformers**: Acceso a modelos preentrenados como FLAN-T5.
- **Sentence Transformers**: GeneraciÃ³n de embeddings para bÃºsqueda semÃ¡ntica.

---

## **ğŸ” Â¿CÃ³mo Funcionan los LLMs en este Proyecto?**
1. **DivisiÃ³n del documento**: El texto se divide en fragmentos manejables.
2. **GeneraciÃ³n de embeddings**: Cada fragmento se convierte en un vector usando `all-mpnet-base-v2`.
3. **BÃºsqueda semÃ¡ntica**: FAISS encuentra los fragmentos mÃ¡s relevantes para la pregunta.
4. **GeneraciÃ³n de respuestas**: **FLAN-T5** recibe los fragmentos relevantes y genera una respuesta coherente y contextualizada.

---

## **ğŸ“‚ Estructura del Proyecto**
