# Chatbot de Soporte T√©cnico Basado en Documentaci√≥n ü§ñ

Un **chatbot de IA** que responde preguntas t√©cnicas basadas en documentaci√≥n, utilizando **LangChain, FAISS y Modelos de Lenguaje Grandes (LLMs)**. Este proyecto demuestra habilidades en **procesamiento de lenguaje natural (NLP), recuperaci√≥n de informaci√≥n y despliegue de modelos generativos**.

---

## **üìå Caracter√≠sticas Clave**
‚úÖ Carga y procesamiento de documentos (PDF, DOCX, TXT).
‚úÖ **B√∫squeda sem√°ntica avanzada** con embeddings y FAISS.
‚úÖ **Generaci√≥n de respuestas contextualizadas** usando **LLMs** (FLAN-T5).
‚úÖ Escalable y adaptable a diferentes dominios t√©cnicos.

---

## **ü§ñ Modelos de Lenguaje Grandes (LLMs) Utilizados**
Este proyecto aprovecha **LLMs** para generar respuestas precisas y detalladas basadas en el contenido de los documentos. Los LLMs son modelos de IA entrenados con grandes cantidades de texto, capaces de entender y generar lenguaje humano de manera coherente.

### **Modelos Utilizados**
| Modelo               | Tipo               | Uso en el Proyecto                                                                 |
|----------------------|--------------------|------------------------------------------------------------------------------------|
| **FLAN-T5 (google/flan-t5-base)** | Modelo de generaci√≥n de texto | Genera respuestas detalladas a preguntas t√©cnicas basadas en el contexto del documento. |
| **Sentence Transformers (all-mpnet-base-v2)** | Modelo de embeddings | Convierte fragmentos de texto en vectores para b√∫squeda sem√°ntica con FAISS.       |

### **¬øPor qu√© FLAN-T5?**
- **FLAN-T5** es un modelo de **instruction tuning** (ajustado para seguir instrucciones), lo que lo hace ideal para tareas de **question-answering** y generaci√≥n de respuestas contextualizadas.
- Es m√°s eficiente que modelos como GPT-3 para tareas espec√≠ficas, y su versi√≥n `base` es lo suficientemente ligera para ejecutarse en entornos con recursos limitados (como Google Colab).

### **¬øPor qu√© Sentence Transformers?**
- **all-mpnet-base-v2** genera **embeddings** (representaciones vectoriales) de alta calidad, permitiendo buscar informaci√≥n relevante en los documentos incluso si las palabras clave no coinciden exactamente.

---

## **üõ† Tecnolog√≠as Utilizadas**
- **LangChain**: Framework para conectar LLMs con fuentes de datos externas.
- **FAISS (Facebook)**: Biblioteca para b√∫squeda eficiente de similitud en espacios vectoriales.
- **Hugging Face Transformers**: Acceso a modelos preentrenados como FLAN-T5.
- **Sentence Transformers**: Generaci√≥n de embeddings para b√∫squeda sem√°ntica.

---

## **üîç ¬øC√≥mo Funcionan los LLMs en este Proyecto?**
1. **Divisi√≥n del documento**: El texto se divide en fragmentos manejables.
2. **Generaci√≥n de embeddings**: Cada fragmento se convierte en un vector usando `all-mpnet-base-v2`.
3. **B√∫squeda sem√°ntica**: FAISS encuentra los fragmentos m√°s relevantes para la pregunta.
4. **Generaci√≥n de respuestas**: **FLAN-T5** recibe los fragmentos relevantes y genera una respuesta coherente y contextualizada.

---
## **üíª Ejemplo de Respuesta Generada por el LLM**
Puedes ver un ejemplo completo de la salida del chatbot en ejemplo_respuesta.txt, donde FLAN-T5 genera una respuesta detallada basada en el contexto del documento.
